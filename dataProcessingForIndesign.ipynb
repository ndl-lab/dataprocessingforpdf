{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# はじめに\n",
    "本ノートはAdobe indesignで2段組に組版されたPDFファイルを対象に、テキストデータを抽出や、機械学習用データセットの作成を支援するツール群です。\n",
    "基本的に上から下へ、Ctrl+Enterキーを押していくことで実行が進みます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDFからxmlの抽出\n",
    "PDFに含まれるテキストを、XML形式で取り出します。このxmlには文字だけでなく、文字の位置の情報や、文字のサイズの情報も含まれています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fileupload\n",
    "from IPython.display import display\n",
    "uploader = fileupload.FileUploadWidget()\n",
    "\n",
    "def _handle_upload(change):\n",
    "    w = change['owner']\n",
    "    with open(w.filename, 'wb') as f:\n",
    "        f.write(w.data)\n",
    "    print('Uploaded `{}` ({:.2f} kB)'.format(\n",
    "        w.filename, len(w.data) / 2**10))\n",
    "\n",
    "uploader.observe(_handle_upload, names='data')\n",
    "print(\"Browseボタンを押して、処理したいPDFファイルを登録して下さい\")\n",
    "display(uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "440it [00:53,  8.18it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import XMLConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "rsrcmgr = PDFResourceManager()\n",
    "laparams = LAParams()\n",
    "laparams.detect_vertical = True\n",
    "os.makedirs(uploader.filename+\"_xml\",exist_ok=True)\n",
    "# 処理するPDFを開く\n",
    "fp = open(uploader.filename, 'rb')\n",
    "for index,page in tqdm(enumerate(PDFPage.get_pages(fp))):\n",
    "    rettxt = BytesIO()\n",
    "    device = XMLConverter(rsrcmgr, rettxt, codec='utf-8', laparams=laparams)\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    interpreter.process_page(page)\n",
    "    content=rettxt.getvalue().decode('utf-8')\n",
    "    with open(uploader.filename+\"_xml\"+os.sep+'{:03d}.xml'.format(index+1), mode='w') as wf:\n",
    "        wf.write(content)\n",
    "    rettxt.close()\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xmlからテキストの抽出\n",
    "\n",
    "xmlのままでは人間にとっては読みづらいので、テキスト化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 440/440 [00:04<00:00, 101.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "作成したテキストをダウンロードする <a href='p001_440.pdf_txt.zip' target='_blank'>p001_440.pdf_txt.zip</a><br>"
      ],
      "text/plain": [
       "/home/t-aoike/aoikedemo/p001_440.pdf_txt.zip"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "xmlfilelist=sorted(glob.glob(uploader.filename+\"_xml\"+os.sep+\"*\"))\n",
    "os.makedirs(uploader.filename+\"_txt\",exist_ok=True)\n",
    "\n",
    "for xmlpath in tqdm(xmlfilelist):\n",
    "    xmlname=os.path.basename(xmlpath)\n",
    "    \n",
    "    f = open(xmlpath, encoding=\"utf-8\")\n",
    "    xmlstringlist = f.readlines()\n",
    "    xmlstrings=\"\".join(xmlstringlist)\n",
    "    f.close()\n",
    "    xmlstrings=xmlstrings.replace(\"<pages>\",\"\")\n",
    "    xmlstrings = xmlstrings.replace(\"\b\", \"\")\n",
    "    #print(xmlstrings)\n",
    "    root = ET.fromstring(xmlstrings)\n",
    "    pageinfo=root.find(\"page\")\n",
    "    resstringlist=[]\n",
    "    cordlist=[]\n",
    "    \n",
    "    _,_,width,height=[float(x) for x in root.get(\"bbox\").split(\",\")]\n",
    "    for index,textbox in enumerate(root.findall('textbox')):\n",
    "        cords=[float(x) for x in textbox.get(\"bbox\").split(\",\")]\n",
    "        x1=width-int(cords[0])\n",
    "        x2=width-int(cords[2])\n",
    "        y2=height-int(cords[1])\n",
    "        y1=height-int(cords[3])\n",
    "        if y1<height/2:\n",
    "            cordlist.append(x1)\n",
    "        else:\n",
    "            cordlist.append(x1+width)\n",
    "        textstring=\"\"\n",
    "        for textline in textbox.findall('textline'):\n",
    "            for text in textline.findall('text'):\n",
    "                if text.text:\n",
    "                    if \"cid\" in text.text:\n",
    "                        textstring+=\"？\"\n",
    "                    else:\n",
    "                        textstring+=text.text.rstrip()\n",
    "        resstringlist.append(textstring)\n",
    "    txtname=xmlname[:-4]+\".txt\"\n",
    "    with open(uploader.filename+\"_txt\"+os.sep+txtname, mode='w') as wf:\n",
    "        for index in np.argsort(np.array(cordlist)):\n",
    "            wf.write(resstringlist[index])\n",
    "import shutil\n",
    "shutil.make_archive(uploader.filename+\"_txt\", 'zip', root_dir=uploader.filename+\"_txt\")\n",
    "from IPython.display import FileLink\n",
    "local_file = FileLink(uploader.filename+\"_txt.zip\", result_html_prefix=\"作成したテキストをダウンロードする-> \")\n",
    "display(local_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ※以下は機械学習用のツール群です"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDFの画像化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "440it [00:18, 24.01it/s]\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install pdf2image\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pdf2image import convert_from_path\n",
    "pdf_path = Path(uploader.filename)\n",
    "# PDF -> Image に変換（150dpi）\n",
    "pages = convert_from_path(str(pdf_path), 150)\n",
    "os.makedirs(uploader.filename+\"_img\",exist_ok=True)\n",
    "# 画像ファイルを１ページずつ保存\n",
    "for index, page in tqdm(enumerate(pages)):\n",
    "    image_path = uploader.filename+\"_img\"+os.sep+'{:03d}.jpg'.format(index+1)\n",
    "    # JPEGで保存\n",
    "    page.save(str(image_path), \"JPEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML文字位置情報を利用したYOLO形式データセットへの変換\n",
    "2段組の組版PDFを1段ごとに分割してYOLO形式に変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "chardic={}\n",
    "os.makedirs(uploader.filename+\"_imgdiv\", exist_ok=True)\n",
    "os.makedirs(uploader.filename+\"_labelsdiv\", exist_ok=True)\n",
    "for imgpath in tqdm(glob.glob(uploader.filename+\"_img/*\")):\n",
    "    \n",
    "    img=cv2.imread(imgpath)\n",
    "    imgheight,imgwidth=img.shape[:2]\n",
    "    imgname=os.path.basename(imgpath)\n",
    "    xmlname=imgname[:-4]+\".xml\"\n",
    "    #print(xmlname)\n",
    "    xmlpath=os.path.join(uploader.filename+\"_xml\",xmlname)\n",
    "    xmlstrings=\"\"\n",
    "    with open(xmlpath, encoding=\"utf-8\") as f:\n",
    "        xmlstringlist = f.readlines()\n",
    "        xmlstrings=\"\".join(xmlstringlist)\n",
    "    xmlstrings=xmlstrings.replace(\"<pages>\",\"\")\n",
    "    xmlstrings = xmlstrings.replace(\"^H\", \"\")\n",
    "    xmlstrings = xmlstrings.replace(\"\b\", \"\")\n",
    "    \n",
    "    root = ET.fromstring(xmlstrings)\n",
    "    _,_,xmlwidth,xmlheight=[float(x) for x in root.get(\"bbox\").split(\",\")]\n",
    "    pageinfo=root.find(\"page\")\n",
    "    encodedf1 = pd.DataFrame(index=[], columns=[\"id\"])\n",
    "    encodedf2 = pd.DataFrame(index=[], columns=[\"id\"])\n",
    "    \n",
    "    for index,textbox in enumerate(root.findall('textbox')):\n",
    "        for textline in textbox.findall('textline'):\n",
    "            for text in textline.findall('text'):\n",
    "                if text.text and text.text.rstrip()!=\"\":\n",
    "                    cords = [float(x) for x in text.get(\"bbox\").split(\",\")]\n",
    "                    x1 = int(cords[0] / xmlwidth* imgwidth) \n",
    "                    x2 = int(cords[2] / xmlwidth * imgwidth) \n",
    "                    y2 = height - int(cords[1] / xmlheight * imgheight)  \n",
    "                    y1 = height - int(cords[3] / xmlheight * imgheight) \n",
    "                    textchar = \"\"\n",
    "                    if \"cid\" in text.text:\n",
    "                        textchar=\"?\"\n",
    "                    elif text.text:\n",
    "                        textchar=text.text.rstrip()\n",
    "                    if not textchar in chardic:\n",
    "                        chardic[textchar]=len(chardic)+1\n",
    "                        #print(len(chardic)+1,textchar)\n",
    "                    if y1 < height // 2:\n",
    "                        centerx=(x1+x2)/(2*width)\n",
    "                        centery = (y1 + y2) / (height//2*2)\n",
    "                        widthp=(x2-x1)/width\n",
    "                        heightp = (y2 - y1) / (height//2)\n",
    "                        textstring=\"%3f %3f %3f %3f\"%(centerx,\n",
    "                                                      centery,widthp,heightp)\n",
    "                        encodedf1 = encodedf1.append(\n",
    "                            pd.Series({\"id\": str(chardic[textchar])+\" \"+textstring}),\n",
    "                            ignore_index=True)\n",
    "                    else:\n",
    "                        y1-=height // 2\n",
    "                        y2-=height // 2\n",
    "                        centerx = (x1 + x2) / (2 * width)\n",
    "                        centery = (y1 + y2) / (height // 2 * 2)\n",
    "                        widthp = (x2 - x1) / width\n",
    "                        heightp = (y2 - y1) / (height // 2)\n",
    "                        textstring = \"%3f %3f %3f %3f\" % (centerx,\n",
    "                                                          centery, widthp, heightp)\n",
    "                        encodedf2 = encodedf2.append(\n",
    "                            pd.Series({\"id\": str(chardic[textchar])+\" \"+textstring}),\n",
    "                            ignore_index=True)\n",
    "    \n",
    "    cv2.imwrite(uploader.filename+\"_imgdiv/\"+imgname[:-4]+\"_1.jpg\",\n",
    "                img[:imgheight//2,:,:])\n",
    "    cv2.imwrite(uploader.filename+\"_imgdiv/\"+imgname[:-4]+\"_2.jpg\",\n",
    "                img[imgheight // 2:,:, :])\n",
    "    encodedf1.to_csv(uploader.filename+\"_labelsdiv/\"+imgname[:-4]+\"_1.txt\",\n",
    "                     index=False,header=None)\n",
    "    encodedf2.to_csv(uploader.filename+\"_labelsdiv/\" + imgname[:-4] + \"_2.txt\", \n",
    "                     index=False, header=None)\n",
    "\n",
    "with open(uploader.filename+'_encodedic.json','w') as f:\n",
    "    json.dump(chardic,f,ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
